{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc78b2e-0fbc-4c93-8cd0-ada24f280db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import Ridge, LinearRegression, RidgeCV\n",
    "from sklearn.model_selection import cross_val_predict, KFold, train_test_split\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import phate, ephate, random, scipy\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE, Isomap\n",
    "from sklearn.metrics import r2_score, confusion_matrix\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from demo_data_helpers import load_simulated_data_manifold_example\n",
    "from sklearn import datasets\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Set seed for reproducibility\n",
    "SEED=4\n",
    "random.seed(4)\n",
    "np.random.seed(4) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f60b1b-66df-4f4a-b494-6c523902eddf",
   "metadata": {},
   "source": [
    "# Toy datasets - when/why do nonlinear datasets result in better embeddings?\n",
    "We're going to start with three publicly available datasets that should provide some visual support for using nonlinear methods to embed certain kinds of data. We're going to look at one linear dimensionality reduction method --- PCA --- and compare it with two nonlinear manifold learning methods -- T-SNE and PHATE. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b2fdfc-ec63-4b2d-9d49-3b1056e9aed9",
   "metadata": {},
   "source": [
    "## Dataset 1: Iris\n",
    "The iris dataset is one of the most classic datasets. It has 150 samples and 4 features, and all of the samples belong to one of three classes. It's a relatively small, low-dimensional, and clean dataset, and its embeddings create linearly separable categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00df0aa2-c043-4d47-8188-6498c7429ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data, iris_labels = datasets.load_iris(return_X_y=True)\n",
    "# normalize the data features across samples\n",
    "iris_data = scipy.stats.zscore(iris_data, axis=1)\n",
    "# embed with PCA, T-SNE, and PHATE -- using each method's default parameters \n",
    "iris_pca = PCA(n_components=2).fit_transform(iris_data)\n",
    "iris_tsne = TSNE(n_components=2,verbose=0).fit_transform(iris_data)\n",
    "iris_phate = phate.PHATE(n_components=2,verbose=0).fit_transform(iris_data)\n",
    "\n",
    "# run a classifier over these embeddings\n",
    "accuracies = []\n",
    "for d in [iris_pca, iris_tsne, iris_phate]:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(d, iris_labels, test_size=0.4, random_state=0)\n",
    "    mod = LinearSVC().fit(X_train,y_train)\n",
    "    acc = mod.score(X_test,y_test)\n",
    "    accuracies.append(acc)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 3))\n",
    "gs = GridSpec(1, 4, width_ratios=[1, 1, 1, 0.2])  # 3 matrices + 1 narrow colorbar\n",
    "\n",
    "uniq_labels = np.unique(iris_labels)\n",
    "palette=sns.color_palette('Set3',len(uniq_labels))\n",
    "color_dict = {group: color for group, color in zip(uniq_labels, palette)}\n",
    "\n",
    "# Create axes for each matrix and colorbar\n",
    "axes = [plt.subplot(gs[i]) for i in range(4)]\n",
    "\n",
    "g=sns.scatterplot(x=iris_pca[:,0], y=iris_pca[:,1], c=iris_labels,  ax=axes[0],s=20, cmap='Set3',legend=False)\n",
    "g.set(xticks=[],yticks=[],title=f'Iris - PCA, acc={np.round(accuracies[0],3)}')\n",
    "\n",
    "g=sns.scatterplot(x=iris_tsne[:,0], y=iris_tsne[:,1], c=iris_labels,  ax=axes[1], s=20, cmap='Set3',legend=False)\n",
    "g.set(xticks=[],yticks=[],title=f'Iris - T-SNE, acc={np.round(accuracies[1],3)}')\n",
    "\n",
    "g=sns.scatterplot(x=iris_phate[:,0], y=iris_phate[:,1], c=iris_labels, ax=axes[2],s=20, cmap='Set3',legend=False)\n",
    "g.set(xticks=[],yticks=[],title=f'Iris - PHATE, acc={np.round(accuracies[2],3)}')\n",
    "\n",
    "axes[3].axis('off')\n",
    "\n",
    "\n",
    "# Create custom legend handles\n",
    "legend_handles = []\n",
    "for group, color in color_dict.items():\n",
    "    handle = Line2D(\n",
    "        [0], [0], \n",
    "        marker='o', \n",
    "        color='w',\n",
    "        markerfacecolor=color, \n",
    "        markersize=10, \n",
    "        label=group\n",
    "    )\n",
    "    legend_handles.append(handle)\n",
    "\n",
    "# Add the legend to the separate axis with adjusted parameters for many groups\n",
    "legend = axes[3].legend(\n",
    "    handles=legend_handles, \n",
    "    loc='center', \n",
    "    fontsize=10 \n",
    "    frameon=True, \n",
    "    title='Class',\n",
    "    ncol=1 \n",
    ")\n",
    "\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1003f0-ad35-4190-83b1-1d4dc0a1b890",
   "metadata": {},
   "source": [
    "What does this show us? well, it appears that these data are quite separable in both linear and nonlinear dimensions -- visually, you can see that the PCs and the nonlinear dimensions all push apart flowers from different groups, and that the green/yellow classes are closer than the purple class, showing that the geometry is preserved across embedding methods. Classification accuracy for all three embeddings is pretty high, too, well above the 33% chance. Though we get better accuracy with the nonlinear embeddings, this is not an overwhelming difference. In all, for this low-dimensional and clean dataset, embedding in nonlinear dimensions does not result in overwhelming improvements!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9804bacc-fbc1-48ea-87f2-685f90bd453e",
   "metadata": {},
   "source": [
    "## Dataset 2: digits\n",
    "What about a higher-dimensional, noiser dataset? Next, let's consider the digits dataset. This dataset contains ~1800 samples and 64 features. The 64 features are a vectorized version of 8x8 pixel images containing handwritten digits, and the goal is to classify the digit written in each image. See more about this dataset [here](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html#sklearn.datasets.load_digits). These data are much noisier and higher dimensional than the Iris dataset, so lets take a look. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dcd7bd-4435-43fc-a5e8-ab7baa5395d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in the dataset from SKLearn\n",
    "digit_data, digit_labels = datasets.load_digits(return_X_y=True)\n",
    "digit_data = np.nan_to_num(scipy.stats.zscore(digit_data, axis=1) )\n",
    "\n",
    "# embed with PCA, T-SNE, and PHATE -- using each method's default parameters \n",
    "digits_pca = PCA(n_components=2).fit_transform(digit_data)\n",
    "digits_tsne = TSNE(n_components=2,verbose=0).fit_transform(digit_data)\n",
    "digits_phate = phate.PHATE(n_components=2,verbose=0).fit_transform(digit_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67b23d4-afe4-453e-8a91-1b83708bac08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a classifier over these embeddings\n",
    "digit_labels = [int(d) for d in digit_labels]\n",
    "accuracies = []\n",
    "confusion_mtx = []\n",
    "for d in [digits_pca, digits_tsne, digits_phate]:\n",
    "    # Not doing any real robust cross-valudation here - just splitting the data once, using 1/4 the samples as test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(d, digit_labels, test_size=0.25, random_state=0)\n",
    "    mod = SVC(kernel='rbf',C=10).fit(X_train,y_train)\n",
    "    acc = mod.score(X_test,y_test)\n",
    "    accuracies.append(acc)\n",
    "    pred = mod.predict(X_test)\n",
    "    confusion_mtx.append([y_test, pred])\n",
    "\n",
    "# now let's set up some plots\n",
    "# Create figure with GridSpec\n",
    "fig = plt.figure(figsize=(13, 4))\n",
    "gs = GridSpec(1, 4, width_ratios=[1, 1, 1, 0.2])  # 3 scatterplots + 1 legend\n",
    "\n",
    "uniq_labels = np.unique(digit_labels)\n",
    "palette=sns.color_palette('Set3', len(uniq_labels))\n",
    "color_dict = {int(group): color for group, color in zip(uniq_labels, palette)}\n",
    "\n",
    "# Create axes for each matrix and colorbar\n",
    "axes = [plt.subplot(gs[i]) for i in range(4)]\n",
    "\n",
    "temp = pd.DataFrame({'x':digits_pca[:,0], 'y':digits_pca[:,1], 'c':digit_labels})\n",
    "g=sns.scatterplot(data=temp, x=\"x\", y=\"y\", hue=\"c\", palette=color_dict, ax=axes[0],s=20,  legend=False)\n",
    "g.set(xticks=[],yticks=[],xlabel='',ylabel='',title=f'Digits - PCA, acc={np.round(accuracies[0],3)}')\n",
    "\n",
    "temp = pd.DataFrame({'x':digits_tsne[:,0], 'y':digits_tsne[:,1], 'c':digit_labels})\n",
    "g=sns.scatterplot(data=temp, x=\"x\", y=\"y\", hue=\"c\",  ax=axes[1], s=20, palette=color_dict, legend=False)\n",
    "g.set(xticks=[],yticks=[],xlabel='',ylabel='',title=f'Digits - T-SNE, acc={np.round(accuracies[1],3)}')\n",
    "\n",
    "temp = pd.DataFrame({'x':digits_phate[:,0], 'y':digits_phate[:,1], 'c':digit_labels})\n",
    "g=sns.scatterplot(data=temp, x=\"x\", y=\"y\", hue=\"c\",  ax=axes[2], s=20, palette=color_dict, legend=False)\n",
    "g.set(xticks=[],yticks=[],xlabel='',ylabel='',title=f'Digits - PHATE, acc={np.round(accuracies[2],3)}')\n",
    "\n",
    "axes[3].axis('off')\n",
    "\n",
    "# Create custom legend handles\n",
    "legend_handles = []\n",
    "for group, color in color_dict.items():\n",
    "    handle = Line2D(\n",
    "        [0], [0], \n",
    "        marker='o', \n",
    "        color='w',\n",
    "        markerfacecolor=color, \n",
    "        markersize=10, \n",
    "        label=group\n",
    "    )\n",
    "    legend_handles.append(handle)\n",
    "\n",
    "# Add the legend to the separate axis with adjusted parameters for many groups\n",
    "legend = axes[3].legend(\n",
    "    handles=legend_handles, \n",
    "    loc='center', \n",
    "    fontsize=10 if len(uniq_labels) > 6 else 12,  # Smaller font for many groups\n",
    "    frameon=True, \n",
    "    title='Digit',\n",
    "    ncol=1 if len(uniq_labels) <= 8 else 1  # Use 2 columns if more than 8 groups\n",
    ")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4add15-2060-40c3-9e4d-9d3e0c4965d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's also look at the mistakes made by each method -- can we see any structure? \n",
    "cmat_pca = confusion_matrix(confusion_mtx[0][0], confusion_mtx[0][1], normalize='true')\n",
    "cmat_tsne = confusion_matrix(confusion_mtx[1][0], confusion_mtx[1][1], normalize='true')\n",
    "cmat_phate = confusion_matrix(confusion_mtx[2][0], confusion_mtx[2][1], normalize='true')\n",
    "\n",
    "# Create figure with GridSpec\n",
    "fig = plt.figure(figsize=(13, 4))\n",
    "gs = GridSpec(1, 4, width_ratios=[1, 1, 1, 0.08])  # 3 matrices + 1 narrow colorbar\n",
    "\n",
    "# Create axes for each matrix and colorbar\n",
    "ax1 = plt.subplot(gs[0])\n",
    "ax2 = plt.subplot(gs[1])\n",
    "ax3 = plt.subplot(gs[2])\n",
    "cbar_ax = plt.subplot(gs[3])  # Separate axis for colorbar\n",
    "\n",
    "# Plot heatmaps without colorbars\n",
    "g1 = sns.heatmap(cmat_pca, ax=ax1, square=True, cbar=False, vmin=0, vmax=1, \n",
    "               cmap='Reds', linewidths=0.5, linecolor='k',mask=cmat_pca==0)\n",
    "g2 = sns.heatmap(cmat_tsne, ax=ax2, square=True, cbar=False, vmin=0, vmax=1, \n",
    "               cmap='Reds', linewidths=0.5, linecolor='k',mask=cmat_tsne==0)\n",
    "g3 = sns.heatmap(cmat_phate, ax=ax3, square=True, cbar=False, vmin=0, vmax=1, \n",
    "               cmap='Reds', linewidths=0.5, linecolor='k',mask=cmat_phate==0)\n",
    "\n",
    "# Add a separate colorbar\n",
    "cbar = fig.colorbar(g3.collections[0], cax=cbar_ax)\n",
    "\n",
    "# Set titles and labels\n",
    "ax1.set_title('Confusion mtx - PCA')\n",
    "ax1.set_ylabel('True digit')\n",
    "ax1.set_xlabel('Predicted digit')\n",
    "\n",
    "ax2.set_title('Confusion mtx - t-SNE')\n",
    "ax2.set_ylabel('')\n",
    "ax2.set_xlabel('Predicted digit')\n",
    "\n",
    "ax3.set_title('Confusion mtx - PHATE')\n",
    "ax3.set_ylabel('')\n",
    "ax3.set_xlabel('Predicted digit')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3190868c-8312-4e98-b752-fe05c05c96a3",
   "metadata": {},
   "source": [
    "In this confusion matrix, we can see which pairs of digits are most commonly confused within each embedding space. The vast majortity of the time, the model predicts the true digit in the t-SNE and PHATE spaces, shown by the diagonal. There are some sparse mistakes in the PHATE and t-SNE matrices, whereas there are more patterned ones in the PCA space -- confusing digits that are pretty visually similar, like 5 and 8 or 7 and 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0f3b70-2b5e-4d02-a2b2-1f626212fb3b",
   "metadata": {},
   "source": [
    "## Dataset 3: Micro-mass\n",
    "This is a dataset from OpenML.org ([link](https://www.openml.org/d/1514)): identification of microorganisms from mass-spectrometry data. For our purposes, this is an example of a high dimesional dataset where there are far more features than samples, more similar to what we'd see in fMRI data, and the data come from 10 microorganisms, resulting in a 10-way classification problem. We can fetch these data using the scikit-learn [function](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_openml)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527bf311-b259-4de3-827c-3afb3adee368",
   "metadata": {},
   "outputs": [],
   "source": [
    "micromass_data, micromass_labels = datasets.fetch_openml(return_X_y=True, data_id=1514)\n",
    "micromass_X, micromass_y = micromass_data.values, [int(i) for i in micromass_labels.values]\n",
    "micromass_X = np.nan_to_num(scipy.stats.zscore(micromass_X, axis=1))\n",
    "print(micromass_X.shape, np.unique(micromass_y, return_counts=True))\n",
    "\n",
    "# embed with PCA, T-SNE, and PHATE \n",
    "X_pca = PCA(n_components=2).fit_transform(micromass_X)\n",
    "X_tsne = TSNE(n_components=2,verbose=0, random_state=0).fit_transform(micromass_X)\n",
    "X_phate = phate.PHATE(n_components=2, verbose=0, knn=20, gamma=-1, t=20).fit_transform(micromass_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea715a92-4d10-48b8-b59b-cb8ac767e118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a classifier over these embeddings\n",
    "accuracies = []\n",
    "confusion_mtx = []\n",
    "\n",
    "for d in [X_pca, X_tsne, X_phate]:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(d, micromass_y, test_size=0.25, random_state=0)\n",
    "    mod = SVC(kernel='rbf', C=10).fit(X_train, y_train)\n",
    "    acc = mod.score(X_test,y_test)\n",
    "    accuracies.append(acc)\n",
    "    pred = mod.predict(X_test)\n",
    "    confusion_mtx.append([y_test, pred])\n",
    "\n",
    "# now let's set up some plots\n",
    "# Create figure with GridSpec\n",
    "fig = plt.figure(figsize=(13, 4))\n",
    "gs = GridSpec(1, 4, width_ratios=[1, 1, 1, 0.2])  # 3 matrices + 1 narrow colorbar\n",
    "\n",
    "uniq_labels = np.unique(y)\n",
    "palette=sns.color_palette('Set3',len(uniq_labels))\n",
    "color_dict = {group: color for group, color in zip(uniq_labels, palette)}\n",
    "\n",
    "# Create axes for each matrix and colorbar\n",
    "axes = [plt.subplot(gs[i]) for i in range(4)]\n",
    "\n",
    "temp = pd.DataFrame({'x':dia_pca[:,0], 'y':dia_pca[:,1], 'c':y})\n",
    "g=sns.scatterplot(data=temp, x=\"x\", y=\"y\", hue=\"c\", palette=color_dict, ax=axes[0],s=25,  legend=False)\n",
    "g.set(xticks=[],yticks=[],xlabel='',ylabel='',title=f'micro-mass - PCA, acc={np.round(accuracies[0],3)}')\n",
    "\n",
    "temp = pd.DataFrame({'x':dia_tsne[:,0], 'y':dia_tsne[:,1], 'c':y})\n",
    "g=sns.scatterplot(data=temp, x=\"x\", y=\"y\", hue=\"c\",  ax=axes[1], s=25, palette=color_dict, legend=False)\n",
    "g.set(xticks=[],yticks=[],xlabel='',ylabel='',title=f'micro-mass - T-SNE, acc={np.round(accuracies[1],3)}')\n",
    "\n",
    "temp = pd.DataFrame({'x':dia_phate[:,0], 'y':dia_phate[:,1], 'c':y})\n",
    "g=sns.scatterplot(data=temp, x=\"x\", y=\"y\", hue=\"c\",  ax=axes[2], s=25, palette=color_dict, legend=False)\n",
    "g.set(xticks=[],yticks=[],xlabel='',ylabel='',title=f'micro-mass - PHATE, acc={np.round(accuracies[2],3)}')\n",
    "\n",
    "axes[3].axis('off')\n",
    "\n",
    "\n",
    "# Create custom legend handles\n",
    "legend_handles = []\n",
    "for group, color in color_dict.items():\n",
    "    handle = Line2D(\n",
    "        [0], [0], \n",
    "        marker='o', \n",
    "        color='w',\n",
    "        markerfacecolor=color, \n",
    "        markersize=10, \n",
    "        label=group\n",
    "    )\n",
    "    legend_handles.append(handle)\n",
    "\n",
    "# Add the legend to the separate axis with adjusted parameters for many groups\n",
    "legend = axes[3].legend(\n",
    "    handles=legend_handles, \n",
    "    loc='center', \n",
    "    fontsize=10 ,\n",
    "    frameon=True, \n",
    "    title='species',\n",
    "    ncol=1 \n",
    ")\n",
    "\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c593d72f-6e35-4959-9a73-baa2b82fe973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's also look at the mistakes made by each method -- can we see any structure? \n",
    "cmat_pca = confusion_matrix(confusion_mtx[0][0], confusion_mtx[0][1],normalize='true')\n",
    "cmat_tsne = confusion_matrix(confusion_mtx[1][0], confusion_mtx[1][1],normalize='true')\n",
    "cmat_phate = confusion_matrix(confusion_mtx[2][0], confusion_mtx[2][1],normalize='true')\n",
    "\n",
    "# Create figure with GridSpec\n",
    "fig = plt.figure(figsize=(13, 4))\n",
    "gs = GridSpec(1, 4, width_ratios=[1, 1, 1, 0.08])  # 3 matrices + 1 narrow colorbar\n",
    "\n",
    "# Create axes for each matrix and colorbar\n",
    "ax1 = plt.subplot(gs[0])\n",
    "ax2 = plt.subplot(gs[1])\n",
    "ax3 = plt.subplot(gs[2])\n",
    "cbar_ax = plt.subplot(gs[3])  # Separate axis for colorbar\n",
    "maxx=1\n",
    "\n",
    "# Plot heatmaps without colorbars\n",
    "g1 = sns.heatmap(cmat_pca, ax=ax1, square=True, cbar=False, vmin=0, vmax=maxx, \n",
    "               cmap='Purples', linewidths=0.5, linecolor='k',mask=cmat_pca==0)\n",
    "g2 = sns.heatmap(cmat_tsne, ax=ax2, square=True, cbar=False, vmin=0, vmax=maxx, \n",
    "               cmap='Purples', linewidths=0.5, linecolor='k',mask=cmat_phate==0)\n",
    "g3 = sns.heatmap(cmat_phate, ax=ax3, square=True, cbar=False, vmin=0, vmax=maxx, \n",
    "               cmap='Purples', linewidths=0.5, linecolor='k',mask=cmat_phate==0)\n",
    "\n",
    "# Add a separate colorbar\n",
    "cbar = fig.colorbar(g3.collections[0], cax=cbar_ax)\n",
    "\n",
    "# Set titles and labels\n",
    "ax1.set_title('Confusion mtx - PCA')\n",
    "ax1.set_ylabel('True species')\n",
    "ax1.set_xlabel('Predicted species')\n",
    "\n",
    "ax2.set_title('Confusion mtx - t-SNE')\n",
    "ax2.set_ylabel('')\n",
    "ax2.set_xlabel('Predicted species')\n",
    "\n",
    "ax3.set_title('Confusion mtx - PHATE')\n",
    "ax3.set_ylabel('')\n",
    "ax3.set_xlabel('Predicted species')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718406b8-73f1-4642-a4a3-9eedbef8c094",
   "metadata": {},
   "source": [
    "Once again, what we're seeing is that the nonlinear methods provide better embedding spaces for predicting the different microorganism species classes -- around a 14\\% improvement over the PCA space. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af771f3a-442b-4986-8408-94834b875d30",
   "metadata": {},
   "source": [
    "# Manifold learning on simulated fMRI datasets \n",
    "Now, we're going to work with some simulated fMRI data, generated to resemble the noise properties of data used in our recent [paper](https://modlab.yale.edu/sites/default/files/files/Buschetal2024.pdf). This is to highlight the benefit of nonlinear, multi-view manifold learning. The X-values are simulated brain activations, one per voxel in a region of interest, for those same 400 participants, so a matrix of shape (400, 100). The y-values are simulated scores for those participants, and the E-values are simulated scores for those same 400 participants on several external features that we think would inform the relationship between X and y. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2945421b-d81a-4ef6-b982-dd07537a74d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = load_simulated_data_manifold_example()\n",
    "\n",
    "# X values are simulated brain data for 400 participants, where each participant has 100 features \n",
    "X_values = loaded_data['input_data']\n",
    "\n",
    "# y values are simulated scores on an external metric (e.g., scores on a mental health metric)\n",
    "y_values = loaded_data['scores']\n",
    "\n",
    "# E values are simulated scores on a variety of external features that we think moderate the brain-behavior relationship\n",
    "E_values = loaded_data['exogenous_data']\n",
    "print(X_values.shape, y_values.shape, E_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ec9265-beca-4493-9c37-5185e21a821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These values should already be z-scored; if not, check\n",
    "for V in [X_values, y_values, E_values]:\n",
    "    print(f'mean close to 0? {np.allclose(np.mean(V,axis=0), 0)}, std close to 1? {np.allclose(np.mean(np.std(V,axis=0)), 1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45257c47-69b8-40d9-ac7a-08926b7d4195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the brain, environment, and score to predict\n",
    "# These show the range of activation values, as well as the distribution of variables and the score to predict.\n",
    "fig,ax=plt.subplots(1,3,figsize=(10,3))\n",
    "g=sns.heatmap(X_values, ax=ax[0], vmin=-4, vmax=4, cmap='PiYG_r')\n",
    "g.set(xticks=[],yticks=[],xlabel='features (voxels)', ylabel='samples (participants)', title='brain data')\n",
    "g=sns.histplot(E_values.T, ax=ax[1], kde=True, bins=20, legend=False, alpha=0.2, linewidth=0)\n",
    "g.set(xlabel='z-score', ylabel='count',  title='exogenous data', ylim=[0,50])\n",
    "g=sns.histplot(y_values, ax=ax[2], kde=True, bins=20, legend=False, alpha=0.2, linewidth=0)\n",
    "g.set(xlabel='z-score', ylabel='',  title='score of interest', ylim=[0,50])\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c01c89-0a6c-4f4f-9ed8-1229cb3a9e6b",
   "metadata": {},
   "source": [
    "These show the range of activation values, as well as the distribution of variables and the score to predict.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d78850a-ccf6-4158-a677-22ae3e65c079",
   "metadata": {},
   "source": [
    "## Dimensionality reduction & manifold learning\n",
    "As we saw before, there are many different approaches to dimensionality reduction. Here, we're going to look at some of the most common approaches and see if the projected spaces represent variance along the scores we're trying to predict.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470aa584-634c-4023-a46b-2b7859827375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dimensionality using PCA, Isomap, T-SNE, PHATE - 2 dimensions for visualization\n",
    "n_components = 2\n",
    "\n",
    "pca_embedding = PCA(n_components=n_components).fit_transform(X_values)\n",
    "iso_embedding = Isomap(n_components=n_components).fit_transform(X_values)\n",
    "tsne_embedding = TSNE(n_components=n_components, random_state=0).fit_transform(X_values)\n",
    "phate_embedding = phate.PHATE(n_components=n_components,verbose=0).fit_transform(X_values)\n",
    "embeddings = [pca_embedding, iso_embedding, tsne_embedding, phate_embedding]\n",
    "titles = ['pca','isomap','tsne','phate']\n",
    "# Create figure with GridSpec\n",
    "fig = plt.figure(figsize=(16, 4))\n",
    "gs = GridSpec(1, 5, width_ratios=[1, 1, 1, 1, 0.08])  # 3 matrices + 1 narrow colorbar\n",
    "\n",
    "# Create axes for each matrix and colorbar\n",
    "ax1 = plt.subplot(gs[0])\n",
    "ax2 = plt.subplot(gs[1])\n",
    "ax3 = plt.subplot(gs[2])\n",
    "ax4 = plt.subplot(gs[3])\n",
    "\n",
    "cbar_ax = plt.subplot(gs[4])  # Separate axis for colorbar\n",
    "for i, ax in enumerate([ax1,ax2,ax3,ax4]):\n",
    "    ax.scatter(embeddings[i][:,0], y=embeddings[i][:,1], s=8, c=y_values)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(f'{titles[i]} embedding')\n",
    "    ax.set_xlabel(f'{titles[i]}1')\n",
    "    ax.set_ylabel(f'{titles[i]}2')\n",
    "    \n",
    "# Add a separate colorbar\n",
    "cbar = fig.colorbar(ax.collections[0], cax=cbar_ax)\n",
    "\n",
    "fig.tight_layout()\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3dfb82-117c-472d-b735-8e0c622dd6ac",
   "metadata": {},
   "source": [
    "Unlike with the toy datasets, we see here that these embedding techniques don't show any sort of clustering related to this variable. But what if we include the external variables? Does including this information help?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efca2f7f-0f48-457c-ab23-c762e467fc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dimensionality using PCA, PHATE, UMAP, and E-PHATE - 2 dimensions for visualization\n",
    "n_components = 2\n",
    "iso_embedding = Isomap(n_components=n_components).fit_transform(X_values)\n",
    "tsne_embedding = TSNE(n_components=n_components, random_state=0).fit_transform(X_values)\n",
    "phate_embedding = phate.PHATE(n_components=n_components,verbose=0).fit_transform(X_values)\n",
    "ephate_embedding = ephate.EPHATE(n_components=n_components,X2_metric='euclidean', verbose=0).fit_transform(X_values, E_values.T)\n",
    "\n",
    "embeddings = [iso_embedding, tsne_embedding, phate_embedding, ephate_embedding]\n",
    "titles = ['isomap','tsne','phate','ephate']\n",
    "# Create figure with GridSpec\n",
    "fig = plt.figure(figsize=(16, 4))\n",
    "gs = GridSpec(1, 5, width_ratios=[1, 1, 1, 1, 0.08])  # 3 matrices + 1 narrow colorbar\n",
    "\n",
    "# Create axes for each matrix and colorbar\n",
    "ax1 = plt.subplot(gs[0])\n",
    "ax2 = plt.subplot(gs[1])\n",
    "ax3 = plt.subplot(gs[2])\n",
    "ax4 = plt.subplot(gs[3])\n",
    "\n",
    "cbar_ax = plt.subplot(gs[4])  # Separate axis for colorbar\n",
    "for i, ax in enumerate([ax1,ax2,ax3,ax4]):\n",
    "    ax.scatter(embeddings[i][:,0], y=embeddings[i][:,1], s=8, c=y_values)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(f'{titles[i]} embedding')\n",
    "    ax.set_xlabel(f'{titles[i]}1')\n",
    "    ax.set_ylabel(f'{titles[i]}2')\n",
    "    \n",
    "# Add a separate colorbar\n",
    "cbar = fig.colorbar(ax.collections[0], cax=cbar_ax)\n",
    "\n",
    "fig.tight_layout()\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca6682e-a05a-453c-8cd2-8337c26afc8e",
   "metadata": {},
   "source": [
    "The EPHATE embedding shows some nice clustering based on participant's scores, showing that the dimensions learned capture variance related to this variable of interest. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce3b4c7-bf16-44e6-9672-ed75f99b2fb7",
   "metadata": {},
   "source": [
    "# Quantifying embedding structure\n",
    "We can quantify how well the embedding reflects a variable of interest by training regression models on one portion of the samples and testing the regression model on another portion of samples (cross-validation). Here, we're using nested KFold cross-validation to select 1) the parameters of a ridge regression model and 2) the number of embedding dimensions that best predict the variable of interest for each embedding type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e02ee2-280c-430b-96b2-8c3f568ee6fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use embeddings to run prediction\n",
    "inner_cv = KFold(n_splits=2)\n",
    "outer_cv = KFold(n_splits=5)\n",
    "\n",
    "results_df = pd.DataFrame(columns=['dimensions','r2','spearmanr','best_alpha','name','fold'])\n",
    "dim2test = [2,3,4,5,6,7,8,10,20]\n",
    "alphas = 10**np.linspace(-4, 10, 15)\n",
    "for n in dim2test:\n",
    "    # fit ephate\n",
    "    pca_embedding = PCA(n_components=n).fit_transform(X_values)\n",
    "    try:\n",
    "        tsne_embedding = TSNE(n_components=n).fit_transform(X_values)\n",
    "    except:\n",
    "        print('')\n",
    "    phate_embedding = phate.PHATE(n_components=n,verbose=0).fit_transform(X_values)\n",
    "    ephate_embedding = ephate.EPHATE(n_components=n,X2_metric='euclidean', verbose=0).fit_transform(X_values, E_values.T)\n",
    "    embeddings = {'pca':pca_embedding, 'tsne': tsne_embedding, 'phate': phate_embedding, 'ephate': ephate_embedding}\n",
    "    for name, data in embeddings.items():\n",
    "        lr_cv = RidgeCV(alphas=alphas,  fit_intercept=True, cv=inner_cv)\n",
    "        lr_cv.fit(data, y_values)\n",
    "        best_alpha = lr_cv.alpha_\n",
    "        # fit a new ridge\n",
    "        fold=0\n",
    "        for train_idx,test_idx in outer_cv.split(np.arange(data.shape[0])):\n",
    "            lr = Ridge(alpha=best_alpha)\n",
    "            lr.fit(data[train_idx], y_values[train_idx])\n",
    "            ypred = lr.predict(data[test_idx])\n",
    "            rsq = r2_score(y_values[test_idx], ypred)\n",
    "            r = scipy.stats.spearmanr(ypred, y_values[test_idx])[0]\n",
    "            results_df.loc[len(results_df)] = {'dimensions':n, 'r2':rsq, 'spearmanr':r, 'best_alpha':best_alpha,'fold':fold, 'name':name}\n",
    "            fold+=1\n",
    "            \n",
    "names = ['mean','voxels']\n",
    "for i, data in enumerate([X_values.mean(axis=1).reshape(-1,1), X_values]):\n",
    "    name = names[i]\n",
    "    # identify the best alpha value\n",
    "    lr_cv = RidgeCV(alphas=alphas,  fit_intercept=True, cv=inner_cv)\n",
    "    lr_cv.fit(data, y_values)\n",
    "    fold=0\n",
    "    for train_idx, test_idx in outer_cv.split(np.arange(data.shape[0])):\n",
    "        lr = Ridge(alpha=best_alpha)\n",
    "        lr.fit(data[train_idx], y_values[train_idx])\n",
    "        ypred = lr.predict(data[test_idx])\n",
    "        rsq = r2_score(y_values[test_idx], ypred)\n",
    "        r = scipy.stats.spearmanr(ypred, y_values[test_idx])[0]\n",
    "        results_df.loc[len(results_df)] = {'dimensions':name, 'r2':rsq, 'spearmanr':r, 'best_alpha':best_alpha,'fold':fold, 'name':name}\n",
    "        fold+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bd360a-dc24-494a-80a1-a4eb3db9ff77",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pointplot(data=results_df, x='dimensions', y='spearmanr', hue='name',\n",
    "              hue_order=['mean','voxels','pca','tsne','phate','ephate'],\n",
    "             palette='Set2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cdc716-8c9a-419e-a640-d799c32366d8",
   "metadata": {},
   "source": [
    "What we see here is that E-PHATE embeddings are vastly more accurate than the other methods, but it really doesn't matter how many dimensions we retain. Let's select a random number of dimensions (4) and run the analysis again "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf4a9b3-88cf-4031-9197-9efae6a7327f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's select one embedding dimensionality (4) and rerun the prediction: \n",
    "k = 4\n",
    "inner_cv = KFold(n_splits=10)\n",
    "alphas = 10**np.linspace(-4, 10, 20)\n",
    "pca_embedding = PCA(n_components=k).fit_transform(X_values)\n",
    "tsne_embedding = TSNE(n_components=3).fit_transform(X_values) # \n",
    "iso_embedding = Isomap(n_components=k).fit_transform(X_values)\n",
    "phate_embedding = phate.PHATE(n_components=k,verbose=0).fit_transform(X_values)\n",
    "ephate_embedding = ephate.EPHATE(n_components=k, X2_metric='euclidean', verbose=0).fit_transform(X_values, E_values.T)\n",
    "xmean = X_values.mean(axis=1).reshape(-1,1) \n",
    "embeddings = {'pca':pca_embedding, 'tsne': tsne_embedding, 'phate': phate_embedding, 'ephate': ephate_embedding, 'isomap':iso_embedding, 'mean':xmean, 'voxels':X_values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac86bc9-72ac-481b-9777-6ccfb0126024",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {}\n",
    "results_df = pd.DataFrame(columns=['spearmanr','name','fold'])\n",
    "outer_cv = KFold(n_splits=10)\n",
    "\n",
    "for name, data in embeddings.items():\n",
    "    # optimize the number of  \n",
    "    rr_cv = RidgeCV(alphas=alphas, cv=inner_cv)\n",
    "    rr_cv.fit(data, y_values)\n",
    "    best_alpha = rr_cv.alpha_\n",
    "    # now set a new model\n",
    "    predictions[name] = np.zeros(len(y_values))\n",
    "    for i,(train,test) in enumerate(outer_cv.split(np.arange(len(y_values)))):\n",
    "        rr = Ridge(alpha=best_alpha)\n",
    "        rr.fit(data[train], y_values[train])\n",
    "        predicted = rr.predict(data[test])\n",
    "        predictions[name][test]=predicted\n",
    "        corr = scipy.stats.spearmanr(y_values[test], predicted)[0]        \n",
    "        results_df.loc[len(results_df)] = {'spearmanr':corr, 'fold':i, 'name':name}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2d860e-7cf9-4b61-a10a-1597bc6bacc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='name', y='spearmanr', data=results_df, hue='name', \n",
    "            hue_order=['mean','voxels','pca','tsne','isomap','phate','ephate'], \n",
    "            order=['mean','voxels','pca','tsne','isomap','phate','ephate'],palette='Set2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cd373d-60d1-4836-be6f-2da55a1c882d",
   "metadata": {},
   "source": [
    "So this is an example of an instance where a mulit-view manifold affords better prediction of the target variable than any of the brain embeddings alone! If you want to read more about these methods, you can look at our [paper](https://modlab.yale.edu/sites/default/files/files/Buschetal2024.pdf) and [python package](https://pypi.org/project/EPHATE/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f76857-2670-47f3-84b3-5fcb63d4d5a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
